## hi, i'm benjamin

I'm a researcher focused on building AI that's aligned with human values. I'm currently a contract researcher at OpenAI working on model evaluations, while also doing technical AI safety research as part of the [ML Alignment & Theory Scholars (MATS) Program](https://www.matsprogram.org). I also work on research related to transportation policy and government-citizen interactions as a Fellow at NYU's [Marron Institute](https://marroninstitute.nyu.edu/). 

- ðŸŒ± Currently working on: LLM evals
- ðŸ’» Recent paper: [CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring](https://arxiv.org/abs/2505.23575), with a high-level overview: [Unfaithful Reasoning Can Fool Chain-of-Thought Monitoring](https://www.alignmentforum.org/posts/QYAfjdujzRv8hx6xo/unfaithful-reasoning-can-fool-chain-of-thought-monitoring)
- ðŸš¦ Read my latest applied ML piece: [Why Does the NYPD Ignore So Many Parking Complaints?](https://www.vitalcitynyc.org/articles/illegal-parking-and-failed-governance-ai-study-of-nypd-enforcement), which was based on this [research](https://www.sciencedirect.com/science/article/abs/pii/S026427512500592X)

Feel free to [get in touch](mailto:github@benjaminarnav.com).
